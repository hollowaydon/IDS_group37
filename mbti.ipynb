{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get spacy and gensim:\n",
    "\n",
    "``conda install -c conda-forge spacy``\\\n",
    "``python -m spacy download en_core_web_lg``\\\n",
    "``conda install -c conda-forge gensim``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('mbti_1.csv')\n",
    "# split_posts = df['posts'].to_string().split('|||')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# break up each row into its constituent sentences\n",
    "# drop any row that has more than 50 sentences (these often have ||||||| in them)\n",
    "l = df['posts'].values.tolist()\n",
    "targets = df['type'].values.tolist()\n",
    "new_list_1 = [x.split('|||') for x in l]\n",
    "\n",
    "for i in range(len(new_list_1)):\n",
    "    new_list_1[i].insert(0, targets[i])\n",
    "    \n",
    "new_list = [x for x in new_list_1 if len(x) <= 51]\n",
    "df_mbti = pd.DataFrame(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_X_train, text_X_test, text_y_train, text_y_test = train_test_split(df_mbti.drop(columns=[0]),\n",
    "                                                    df_mbti[0],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 123)\n",
    "\n",
    "# reshape train data so each sentence is on its own row, remove Nones\n",
    "text_X_train = text_X_train.to_numpy().reshape(-1,1)\n",
    "text_y_train = np.c_[[text_y_train for i in range(50)]].T.reshape(-1,1)\n",
    "text_train_data = np.c_[text_y_train, text_X_train]\n",
    "text_train_data = text_train_data[text_train_data[:,1] != None]\n",
    "\n",
    "text_X_test = text_X_test.to_numpy().reshape(-1,1)\n",
    "text_y_test = np.c_[[text_y_test for i in range(50)]].T.reshape(-1,1)\n",
    "text_test_data = np.c_[text_y_test, text_X_test]\n",
    "text_test_data = text_test_data[text_test_data[:,1] != None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [0 for x in text_test_data[:,0]]\n",
    "y_1 = [np.zeros(4) for x in text_test_data[:,0]]\n",
    "for i in range(len(y_test)):\n",
    "    if text_test_data[i,0][0] == \"I\":\n",
    "        y_test[i] += 1\n",
    "        y_1[i][0] += 1\n",
    "    if text_test_data[i,0][1] == \"S\":\n",
    "        y_test[i] += 2\n",
    "        y_1[i][1] += 1\n",
    "    if text_test_data[i,0][2] == \"T\":\n",
    "        y_test[i] += 4\n",
    "        y_1[i][2] += 1\n",
    "    if text_test_data[i,0][3] == \"F\":\n",
    "        y_test[i] += 8\n",
    "        y_1[i][3] += 1\n",
    "        \n",
    "y_train = [0 for x in text_train_data[:,0]]\n",
    "y_2 = [np.zeros(4) for x in text_train_data[:,0]]\n",
    "for i in range(len(y_train)):\n",
    "    if text_train_data[i,0][0] == \"I\":\n",
    "        y_train[i] += 1\n",
    "        y_2[i][0] += 1\n",
    "    if text_train_data[i,0][1] == \"S\":\n",
    "        y_train[i] += 2\n",
    "        y_2[i][1] += 1\n",
    "    if text_train_data[i,0][2] == \"T\":\n",
    "        y_train[i] += 4\n",
    "        y_2[i][2] += 1\n",
    "    if text_train_data[i,0][3] == \"F\":\n",
    "        y_train[i] += 8\n",
    "        y_2[i][3] += 1\n",
    "\n",
    "y_2 = np.array(y_2)\n",
    "y_1 = np.array(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7526058514844368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text_train_data[:,1])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_2[:,0])\n",
    "\n",
    "X_1 = count_vect.transform(text_test_data[:,1])\n",
    "X_2 = tfidf_transformer.fit_transform(X_1)\n",
    "X_new_counts = count_vect.transform(text_test_data[:,1])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "print(clf.score(X_new_tfidf, y_1[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526465866340786\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text_train_data[:,1])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_2[:,1])\n",
    "\n",
    "X_1 = count_vect.transform(text_test_data[:,1])\n",
    "X_2 = tfidf_transformer.fit_transform(X_1)\n",
    "X_new_counts = count_vect.transform(text_test_data[:,1])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "print(clf.score(X_new_tfidf, y_1[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5962188196391345\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text_train_data[:,1])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_2[:,2])\n",
    "\n",
    "X_1 = count_vect.transform(text_test_data[:,1])\n",
    "X_2 = tfidf_transformer.fit_transform(X_1)\n",
    "X_new_counts = count_vect.transform(text_test_data[:,1])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "print(clf.score(X_new_tfidf, y_1[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text_train_data[:,1])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_2[:,3])\n",
    "\n",
    "X_1 = count_vect.transform(text_test_data[:,1])\n",
    "X_2 = tfidf_transformer.fit_transform(X_1)\n",
    "X_new_counts = count_vect.transform(text_test_data[:,1])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "print(clf.score(X_new_tfidf, y_1[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3908297989600556\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text_train_data[:,1])\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "X_1 = count_vect.transform(text_test_data[:,1])\n",
    "X_2 = tfidf_transformer.fit_transform(X_1)\n",
    "X_new_counts = count_vect.transform(text_test_data[:,1])\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "print(clf.score(X_new_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
